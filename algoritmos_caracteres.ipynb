{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNKlgA6chETl1WlYYSvkM9S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"174468f688b549fda92eb4123da5826b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_aa1fbf661f8947759d2e639846a2e86f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1a6d00f7cc324455a67cec57397e8934","IPY_MODEL_b3e80b40e113439ab93848d020761aa8","IPY_MODEL_601769bdbcd84e07877889f61d34ad99"]}},"aa1fbf661f8947759d2e639846a2e86f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1a6d00f7cc324455a67cec57397e8934":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_76cbf693701146e48957f5fdeec1a40d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1ca43068b5334808a94d0fc2b880c30b"}},"b3e80b40e113439ab93848d020761aa8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0a8630b85f6e4633aaff7edd0e8b6956","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1912529,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1912529,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_380982fb62f4480fa4c395babf3b755c"}},"601769bdbcd84e07877889f61d34ad99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cc073b13b3824bb1b1413908b1d4ba45","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.91M/1.91M [00:00&lt;00:00, 5.39MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8da10083fa9140788d58f778bf1e1374"}},"76cbf693701146e48957f5fdeec1a40d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1ca43068b5334808a94d0fc2b880c30b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a8630b85f6e4633aaff7edd0e8b6956":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"380982fb62f4480fa4c395babf3b755c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cc073b13b3824bb1b1413908b1d4ba45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8da10083fa9140788d58f778bf1e1374":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4f63a35873e64d868e29a6c444ba27f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e29772a1fe6c4426a04dacf3880c6ca6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d1d17f1c3f934300b5cd04010a7958f8","IPY_MODEL_e2b9e087263147288e38f6eb3d16d9ba","IPY_MODEL_c5de8107c65c4fc798db383cc618b225"]}},"e29772a1fe6c4426a04dacf3880c6ca6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d1d17f1c3f934300b5cd04010a7958f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5d93babef9a94ef981546d06ae26789e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_139860e548be4cc78f74f24c46f01006"}},"e2b9e087263147288e38f6eb3d16d9ba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3baf725c56854493ae631d6609a87787","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":65,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":65,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a6464a8644564d76957bc22ae5ab53ec"}},"c5de8107c65c4fc798db383cc618b225":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ba1d34f044c04e9786944f1a399e8540","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 65.0/65.0 [00:00&lt;00:00, 2.29kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2b1f697f97934461bd63df6570927598"}},"5d93babef9a94ef981546d06ae26789e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"139860e548be4cc78f74f24c46f01006":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3baf725c56854493ae631d6609a87787":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a6464a8644564d76957bc22ae5ab53ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ba1d34f044c04e9786944f1a399e8540":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2b1f697f97934461bd63df6570927598":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a2df82469ef44ef78ccddc83bab8e591":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d3c7d1e9414e48ea985a365a65bed999","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d8ae41ca0e8845f68fc35c09f0401641","IPY_MODEL_de180292938a495f8249a3ce08b30da0","IPY_MODEL_4f8a5d899e924067b56a2381496b97d8"]}},"d3c7d1e9414e48ea985a365a65bed999":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d8ae41ca0e8845f68fc35c09f0401641":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_63a87bd7f4df48d19524e142749bdfeb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9591d184e42e4a9090a5a0ebe1568fa4"}},"de180292938a495f8249a3ce08b30da0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ea266fe7138f487abf61185361019664","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":86,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":86,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_305e435fef9342818b77fc23b143bdec"}},"4f8a5d899e924067b56a2381496b97d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ef4c7d4d429f40d7bc7aa3c575fc25df","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 86.0/86.0 [00:00&lt;00:00, 3.16kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3758e8fb66534b52aab26259dce276dc"}},"63a87bd7f4df48d19524e142749bdfeb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9591d184e42e4a9090a5a0ebe1568fa4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ea266fe7138f487abf61185361019664":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"305e435fef9342818b77fc23b143bdec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef4c7d4d429f40d7bc7aa3c575fc25df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3758e8fb66534b52aab26259dce276dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b0e0415f8674f5483cd09ecf82979b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ae324105c609467087905fc68066359a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8311a02872fd4cbdb7ce11bb84dbec93","IPY_MODEL_4c62cdf4e3954730b4d011a5191da502","IPY_MODEL_de144dfbd8e044dda94e251a19a7cf9c"]}},"ae324105c609467087905fc68066359a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8311a02872fd4cbdb7ce11bb84dbec93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bd4a1ca84d384cde925f7fe33fd2b6cd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa3ea8dbee924c7994d5624bf704dc73"}},"4c62cdf4e3954730b4d011a5191da502":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_20cd46e0a1b4417faa7ef9a3a72099f1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1142,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1142,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0d84cf031abf417d8a3b3d8e9f2bef9f"}},"de144dfbd8e044dda94e251a19a7cf9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6185df4614c949e6b6685dc677fe3099","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.14k/1.14k [00:00&lt;00:00, 30.9kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e4f023e316d24ddbad3fca289b612eff"}},"bd4a1ca84d384cde925f7fe33fd2b6cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aa3ea8dbee924c7994d5624bf704dc73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"20cd46e0a1b4417faa7ef9a3a72099f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0d84cf031abf417d8a3b3d8e9f2bef9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6185df4614c949e6b6685dc677fe3099":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e4f023e316d24ddbad3fca289b612eff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"26990e96776a4314a857cc3bc447b545":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8a2648e0d4154f9088ae2e2033daca56","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_38153caae281418ca03a4c9f0d711ed2","IPY_MODEL_2ba54c2ec032438c91378e463b675a20","IPY_MODEL_28a447f4efbc4bc489d8868e052e4f7e"]}},"8a2648e0d4154f9088ae2e2033daca56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"38153caae281418ca03a4c9f0d711ed2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1f038b68c9b44e9bb2b5122c4efa0a68","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_211a65bab75841fcb9301796974cd7b3"}},"2ba54c2ec032438c91378e463b675a20":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8b28c20100fb4b0ab50880ecb50550ad","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2275437102,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2275437102,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3e38d3371bc44cb5b437a4c5c82c5d5d"}},"28a447f4efbc4bc489d8868e052e4f7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7f1a7c0f133346d99644e07517627781","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.28G/2.28G [00:56&lt;00:00, 35.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a459cd1031ab42dfa86d6dc164748a87"}},"1f038b68c9b44e9bb2b5122c4efa0a68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"211a65bab75841fcb9301796974cd7b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8b28c20100fb4b0ab50880ecb50550ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3e38d3371bc44cb5b437a4c5c82c5d5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7f1a7c0f133346d99644e07517627781":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a459cd1031ab42dfa86d6dc164748a87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5224058c117443108c02bd457b29f731":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_93589884d14a4b3382259f29f0db381b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c0c1eb5ba5c9452d85bffc3d5de75b46","IPY_MODEL_5373a7131efb4d1bb5efeff485bdaba4","IPY_MODEL_394ae76084594caabb2cfbd43c612312"]}},"93589884d14a4b3382259f29f0db381b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c0c1eb5ba5c9452d85bffc3d5de75b46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1546fdb4142443a4ba4eeca674302013","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_756155c2d92840a4afc84cf04656ac1d"}},"5373a7131efb4d1bb5efeff485bdaba4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_58d2dee7e8c1441cb257a49dac2e00d4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ad77e336b6b24202a46cc2779c8f61c2"}},"394ae76084594caabb2cfbd43c612312":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2fd67847caa04a86b4b04dc3d4e78ff2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:00&lt;00:00, 21.8kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2799cfdb20d443548d552b0fe17bd138"}},"1546fdb4142443a4ba4eeca674302013":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"756155c2d92840a4afc84cf04656ac1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"58d2dee7e8c1441cb257a49dac2e00d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ad77e336b6b24202a46cc2779c8f61c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2fd67847caa04a86b4b04dc3d4e78ff2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2799cfdb20d443548d552b0fe17bd138":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"94835b0a263b4bc7ad8177d2ba3b3b9b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b6443a075571443ea26e161aa60ceb5f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c12c5dbdc28a4b97876a563a3a73bc2b","IPY_MODEL_135be3b61a1e46128988349461c1b5de","IPY_MODEL_aa4a150b4bba4ceaa6660b9917c990b7"]}},"b6443a075571443ea26e161aa60ceb5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c12c5dbdc28a4b97876a563a3a73bc2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0390638c6fd94017aeb38464c0392529","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b1ad443897f7410b814a1a8ad70cc4b9"}},"135be3b61a1e46128988349461c1b5de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_89e452197cbf4605825791ef6f3a570a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":435779157,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435779157,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_780151015e684d28b36faf3f5a2ca888"}},"aa4a150b4bba4ceaa6660b9917c990b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_96e8d093fab44e1e94ab6b1fd45f5279","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 416M/416M [00:09&lt;00:00, 52.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_01df66db0eff4dce960c7a66331396cf"}},"0390638c6fd94017aeb38464c0392529":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b1ad443897f7410b814a1a8ad70cc4b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"89e452197cbf4605825791ef6f3a570a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"780151015e684d28b36faf3f5a2ca888":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"96e8d093fab44e1e94ab6b1fd45f5279":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"01df66db0eff4dce960c7a66331396cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cf5afd7578d042739f31f50838833ece":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5a46a208a9a642858361c88f69ea7972","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_78881852226740849cc207444a726042","IPY_MODEL_2f099e3f39434836830d7d6c5dbb3faf","IPY_MODEL_6aadebddc9db4d33a45f47f1f83512f1"]}},"5a46a208a9a642858361c88f69ea7972":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78881852226740849cc207444a726042":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2af7b6ee28cd4f298ac88b135811c05b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_20b84a02341149219340f46027891a47"}},"2f099e3f39434836830d7d6c5dbb3faf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_faeb3968f37146a6866aa26664fe6252","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":29,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4157e3f05fb04e0aafcdc31bf58b1955"}},"6aadebddc9db4d33a45f47f1f83512f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5b7f665f1bee477a98ba85a1988fad09","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29.0/29.0 [00:00&lt;00:00, 1.04kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_405faf06ba7740b8ba11c6cb33c43703"}},"2af7b6ee28cd4f298ac88b135811c05b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"20b84a02341149219340f46027891a47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"faeb3968f37146a6866aa26664fe6252":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4157e3f05fb04e0aafcdc31bf58b1955":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b7f665f1bee477a98ba85a1988fad09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"405faf06ba7740b8ba11c6cb33c43703":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f4a11b417aeb468baa1cc1b25bdedf60":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_187654f0d8834e6e9353492c3ea1abee","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9851ce9ff2e54843a9bf535b8afdf716","IPY_MODEL_95dbbd7cfa3240d6a95eb192dda20bd8","IPY_MODEL_6e271893d7b543d0978bc95ebbc0eb04"]}},"187654f0d8834e6e9353492c3ea1abee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9851ce9ff2e54843a9bf535b8afdf716":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d4fa9cb032db4c1383d767c15593ae9c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a387d888632f4f15adf514b0fa6c8024"}},"95dbbd7cfa3240d6a95eb192dda20bd8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d998db54667a4babbb8772540c1d4123","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_812f7e8e492c4f98b0098fb685150035"}},"6e271893d7b543d0978bc95ebbc0eb04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cb7d465db4474d2f8b163b41c9b5e3d2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 208k/208k [00:00&lt;00:00, 631kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e8d8c05fe9924a8096817bf8c2190694"}},"d4fa9cb032db4c1383d767c15593ae9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a387d888632f4f15adf514b0fa6c8024":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d998db54667a4babbb8772540c1d4123":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"812f7e8e492c4f98b0098fb685150035":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cb7d465db4474d2f8b163b41c9b5e3d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e8d8c05fe9924a8096817bf8c2190694":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"13ad5f23ff4d420b9689ec4e5602fb75":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_41688f42fcef4486b7e0241e68910b62","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_92544db6b9984f8b88991f41efe07a36","IPY_MODEL_a3cbb66c5f8441c28926430ee7dd7ea0","IPY_MODEL_8b653de4e7c74de38d507d0fd5c7056d"]}},"41688f42fcef4486b7e0241e68910b62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"92544db6b9984f8b88991f41efe07a36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_347377283f384789ba461706d1f425bd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_081d42aa34284d8bb344a7c231a4987d"}},"a3cbb66c5f8441c28926430ee7dd7ea0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4c681ff2db4541ab831e1d34f08760ec","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":435797,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435797,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7d2080a4a6ec4188b974d03e0cf4862a"}},"8b653de4e7c74de38d507d0fd5c7056d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_310596e2bae94c00ac88d73a43793b8a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 426k/426k [00:00&lt;00:00, 1.26MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_75db0d9b375e406483978e52997ba08b"}},"347377283f384789ba461706d1f425bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"081d42aa34284d8bb344a7c231a4987d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4c681ff2db4541ab831e1d34f08760ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7d2080a4a6ec4188b974d03e0cf4862a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"310596e2bae94c00ac88d73a43793b8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"75db0d9b375e406483978e52997ba08b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jPv37k5O50xx","executionInfo":{"status":"ok","timestamp":1682209589472,"user_tz":180,"elapsed":8152,"user":{"displayName":"Lucas Pellicer","userId":"14189643127010164185"}},"outputId":"b3aade7e-560b-4e35-a3db-2117e777017a"},"source":["! pip install numpy git+https://github.com/makcedward/nlpaug.git"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/makcedward/nlpaug.git\n","  Cloning https://github.com/makcedward/nlpaug.git to /tmp/pip-req-build-as5njk9s\n","  Running command git clone --filter=blob:none --quiet https://github.com/makcedward/nlpaug.git /tmp/pip-req-build-as5njk9s\n","  Resolved https://github.com/makcedward/nlpaug.git to commit 23800cbb9632c7fc8c4a88d46f9c4ecf68a96299\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from nlpaug==1.1.11) (1.5.3)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.9/dist-packages (from nlpaug==1.1.11) (2.27.1)\n","Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from nlpaug==1.1.11) (4.6.6)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown>=4.0.0->nlpaug==1.1.11) (4.11.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown>=4.0.0->nlpaug==1.1.11) (4.65.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown>=4.0.0->nlpaug==1.1.11) (1.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown>=4.0.0->nlpaug==1.1.11) (3.11.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.2.0->nlpaug==1.1.11) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.2.0->nlpaug==1.1.11) (2.8.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->nlpaug==1.1.11) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->nlpaug==1.1.11) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->nlpaug==1.1.11) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->nlpaug==1.1.11) (2.0.12)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug==1.1.11) (2.4.1)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->nlpaug==1.1.11) (1.7.1)\n","Building wheels for collected packages: nlpaug\n","  Building wheel for nlpaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nlpaug: filename=nlpaug-1.1.11-py3-none-any.whl size=405902 sha256=a1bb35dc4422bd66553efa8c28beb93e070df6ac08ac199cf86de4911ebc4ed4\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-jlzo9hq2/wheels/90/bc/37/e55b295d36cbaaaf8394dbd355d28e033e236d2bcc7cf77f3a\n","Successfully built nlpaug\n","Installing collected packages: nlpaug\n","Successfully installed nlpaug-1.1.11\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i96g00iH59Uz","executionInfo":{"status":"ok","timestamp":1682209606088,"user_tz":180,"elapsed":12923,"user":{"displayName":"Lucas Pellicer","userId":"14189643127010164185"}},"outputId":"bed31495-c4d8-4614-c702-0796165ecba0"},"source":["! pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n"]}]},{"cell_type":"markdown","metadata":{"id":"SWT4-UNf6EWq"},"source":["Algoritmos Caracteres"]},{"cell_type":"code","source":["import nlpaug.augmenter.char as nac"],"metadata":{"id":"-pLC2lK0hXQI","executionInfo":{"status":"ok","timestamp":1682209875133,"user_tz":180,"elapsed":4955,"user":{"displayName":"Lucas Pellicer","userId":"14189643127010164185"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["text = \"Eu adoro NLP e treinar modelos como BERT!\""],"metadata":{"id":"9o62O6JGhXTw","executionInfo":{"status":"ok","timestamp":1682209992249,"user_tz":180,"elapsed":3,"user":{"displayName":"Lucas Pellicer","userId":"14189643127010164185"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["aug = nac.RandomCharAug()\n","augmented_texts = aug.augment(text, n=3)\n","print(\"Original:\")\n","print(text)\n","print(\"Augmented Texts:\")\n","print(augmented_texts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSdHZv2RhXXN","executionInfo":{"status":"ok","timestamp":1682209993908,"user_tz":180,"elapsed":12,"user":{"displayName":"Lucas Pellicer","userId":"14189643127010164185"}},"outputId":"be04be85-13f6-47bc-a7ce-d81451fa2f7a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:\n","Eu adoro NLP e treinar modelos como BERT!\n","Augmented Texts:\n","['Eu adoro NLP e treinar ^odWloX _omu 9GRT!', 'Eu +d1ro NLP e O2eina1 doJ4los como BERT!', 'Eu ado8% NLP e !re^tar modelos como sEvT!']\n"]}]},{"cell_type":"code","source":["aug = nac.KeyboardAug()  \n","augmented_texts = aug.augment(text, n=3)\n","print(\"Original:\")\n","print(text)\n","print(\"Augmented Texts:\")\n","print(augmented_texts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3i2Qa-f1hXak","executionInfo":{"status":"ok","timestamp":1682210208050,"user_tz":180,"elapsed":786,"user":{"displayName":"Lucas Pellicer","userId":"14189643127010164185"}},"outputId":"b942e56a-7f98-4294-efa9-d22e8dc52170"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:\n","Eu adoro NLP e treinar modelos como BERT!\n","Augmented Texts:\n","['Eu aF8ro NLP e treinar modelos co,l fER%!', 'Eu adoro NLP e treinar moFel*d d9mo nWRT!', 'Eu ad8rl NLP e treinar mKdeOls como hERg!']\n"]}]},{"cell_type":"code","source":["aug = nac.OcrAug()\n","augmented_texts = aug.augment(text, n=3)\n","print(\"Original:\")\n","print(text)\n","print(\"Augmented Texts:\")\n","print(augmented_texts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xbt9e5Wni0lS","executionInfo":{"status":"ok","timestamp":1682210267743,"user_tz":180,"elapsed":8,"user":{"displayName":"Lucas Pellicer","userId":"14189643127010164185"}},"outputId":"623802a7-2579-425d-b0ec-e9b6ac067bc2"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:\n","Eu adoro NLP e treinar modelos como BERT!\n","Augmented Texts:\n","['Bo adoro NLP e tkeinak modelos como BERT!', 'Eu adoro NLP e treinar modelos c0m0 BERT!', 'Eu adoro NLP e treinar mude10s como BERT!']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"1YdBbOZBhXd5"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BndapZbw6DlC"},"source":["\n","import nlpaug.augmenter.word as naw\n","import nlpaug.flow as naf\n","\n","from nlpaug.util import Method"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gKnEYlN66Tmb"},"source":["from nlpaug.augmenter.word import WordAugmenter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y0PiYnkN6eij"},"source":["class GoogleBackTranslationAug(WordAugmenter):\n","    # https://arxiv.org/pdf/1511.06709.pdf\n","    \"\"\"\n","    Augmenter that leverage two translation models for augmentation. For example, the source is English. This\n","    augmenter translate source to German and translating it back to English. For detail, you may visit\n","    https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28\n","    :param str from_model_name: Any model from https://huggingface.co/models?filter=translation&search=Helsinki-NLP. As\n","        long as from_model_name is pair with to_model_name. For example, from_model_name is English to Japanese,\n","        then to_model_name should be Japanese to English.\n","    :param str to_model_name: Any model from https://huggingface.co/models?filter=translation&search=Helsinki-NLP.\n","    :param str device: Default value is CPU. If value is CPU, it uses CPU for processing. If value is CUDA, it uses GPU\n","        for processing. Possible values include 'cuda' and 'cpu'. (May able to use other options)\n","    :param bool force_reload: Force reload the contextual word embeddings model to memory when initialize the class.\n","        Default value is False and suggesting to keep it as False if performance is the consideration.\n","    :param int batch_size: Batch size.\n","    :param int max_length: The max length of output text.\n","    :param str name: Name of this augmenter\n","    >>> import nlpaug.augmenter.word as naw\n","    >>> aug = naw.BackTranslationAug()\n","    \"\"\"\n","\n","    def __init__(self, from_lang='en', to_lang='pt',\n","        name='GoogleBackTranslationAug'):\n","        super().__init__(\n","            action='substitute')\n","\n","        self.src = from_lang\n","        self.dest = to_lang\n","\n","    def substitute(self, data):\n","        from googletrans import Translator\n","\n","        translator = Translator()\n","\n","        result = translator.translate(data, src = self.src, dest=self.dest)\n","\n","        fim = translator.translate(result.text, src = self.dest, dest = self.src)\n","\n","        return fim.text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nZtJGajw8G1W"},"source":["text = 'Filme é muito bom e tem atuações excelentes.'\n","aug = GoogleBackTranslationAug(from_lang='pt', to_lang='fr')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rBuwJj5E8G8z","executionInfo":{"status":"ok","timestamp":1630178625458,"user_tz":180,"elapsed":875,"user":{"displayName":"Lucas Pellicer","photoUrl":"","userId":"14189643127010164185"}},"outputId":"16d462a0-2bac-42c1-a896-5df307a91c75"},"source":["aug.augment(text,5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['O filme é muito bom e tem ótima atuação.',\n"," 'O filme é muito bom e tem ótima atuação.',\n"," 'O filme é muito bom e tem ótima atuação.',\n"," 'O filme é muito bom e tem ótima atuação.',\n"," 'O filme é muito bom e tem ótima atuação.']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"RHX8qmaI8HCK"},"source":["class DeepGoogleBackTranslationAug(WordAugmenter):\n","    # https://arxiv.org/pdf/1511.06709.pdf\n","    \"\"\"\n","    Augmenter that leverage two translation models for augmentation. For example, the source is English. This\n","    augmenter translate source to German and translating it back to English. For detail, you may visit\n","    https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28\n","    :param str from_model_name: Any model from https://huggingface.co/models?filter=translation&search=Helsinki-NLP. As\n","        long as from_model_name is pair with to_model_name. For example, from_model_name is English to Japanese,\n","        then to_model_name should be Japanese to English.\n","    :param str to_model_name: Any model from https://huggingface.co/models?filter=translation&search=Helsinki-NLP.\n","    :param str device: Default value is CPU. If value is CPU, it uses CPU for processing. If value is CUDA, it uses GPU\n","        for processing. Possible values include 'cuda' and 'cpu'. (May able to use other options)\n","    :param bool force_reload: Force reload the contextual word embeddings model to memory when initialize the class.\n","        Default value is False and suggesting to keep it as False if performance is the consideration.\n","    :param int batch_size: Batch size.\n","    :param int max_length: The max length of output text.\n","    :param str name: Name of this augmenter\n","    >>> import nlpaug.augmenter.word as naw\n","    >>> aug = naw.BackTranslationAug()\n","    \"\"\"\n","\n","    def __init__(self, from_lang='en', all_langs=['fr','pt'],\n","        name='DeepGoogleBackTranslationAug'):\n","        super().__init__(\n","            action='substitute')\n","\n","        self.src = from_lang\n","        self.langs = [self.src] + all_langs\n","\n","    def substitute(self, data, n=1):\n","        from googletrans import Translator\n","\n","        translator = Translator()\n","        tam = len(self.langs)\n","        texto = data\n","\n","        for i in range(tam - 1):\n","          result = translator.translate(texto, src = self.langs[i], dest=self.langs[i+1])\n","          texto = result.text\n","        \n","        self.langs.reverse()\n","\n","        for i in range(tam - 1):\n","          result = translator.translate(texto, src = self.langs[i], dest=self.langs[i+1])\n","          texto = result.text\n","\n","        return texto"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pdUyN59duuEd"},"source":["class M2M100BackTranslationAug(WordAugmenter):\n","    # https://arxiv.org/pdf/1511.06709.pdf\n","    \"\"\"\n","    Augmenter that leverage two translation models for augmentation. For example, the source is English. This\n","    augmenter translate source to German and translating it back to English. For detail, you may visit\n","    https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28\n","    :param str from_model_name: Any model from https://huggingface.co/models?filter=translation&search=Helsinki-NLP. As\n","        long as from_model_name is pair with to_model_name. For example, from_model_name is English to Japanese,\n","        then to_model_name should be Japanese to English.\n","    :param str to_model_name: Any model from https://huggingface.co/models?filter=translation&search=Helsinki-NLP.\n","    :param str device: Default value is CPU. If value is CPU, it uses CPU for processing. If value is CUDA, it uses GPU\n","        for processing. Possible values include 'cuda' and 'cpu'. (May able to use other options)\n","    :param bool force_reload: Force reload the contextual word embeddings model to memory when initialize the class.\n","        Default value is False and suggesting to keep it as False if performance is the consideration.\n","    :param int batch_size: Batch size.\n","    :param int max_length: The max length of output text.\n","    :param str name: Name of this augmenter\n","    >>> import nlpaug.augmenter.word as naw\n","    >>> aug = naw.BackTranslationAug()\n","    \"\"\"\n","\n","    def __init__(self, from_lang='en', to_lang='pt',\n","        name='M2M100BackTranslationAug'):\n","        super().__init__(\n","            action='substitute')\n","        \n","        from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n","\n","        model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n","        tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n","\n","        self.src = from_lang\n","        self.dest = to_lang\n","        self.model = model\n","        self.tokenizer = tokenizer\n","\n","    def substitute(self, data, n=1):\n","\n","        self.tokenizer.src_lang = self.src\n","        encoded_hi = self.tokenizer(data, return_tensors=\"pt\")\n","        generated_tokens = self.model.generate(**encoded_hi, forced_bos_token_id=self.tokenizer.get_lang_id(self.dest))\n","        resultado = self.tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n","\n","        self.tokenizer.src_lang = self.dest\n","        encoded_hi2 = self.tokenizer(resultado, return_tensors=\"pt\")\n","        generated_tokens = self.model.generate(**encoded_hi2, forced_bos_token_id=self.tokenizer.get_lang_id(self.src))\n","        texto = self.tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n","\n","        return texto"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SdIP8mHB9Nzq"},"source":["text = 'Filme é muito bom e tem atuações excelentes.'\n","aug = M2M100BackTranslationAug(from_lang='pt', to_lang='fr')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R4wRh5Qs9ZkF","executionInfo":{"status":"ok","timestamp":1628647725915,"user_tz":180,"elapsed":8770,"user":{"displayName":"Lucas Pellicer","photoUrl":"","userId":"14189643127010164185"}},"outputId":"b26902d4-4a01-4b84-845f-32b576219bb2"},"source":["aug.augment(text)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['O filme é muito bom e tem excelentes performances.']"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"xw_n_0gswZzW"},"source":["class DeepM2M100BackTranslationAug(WordAugmenter):\n","    # https://arxiv.org/pdf/1511.06709.pdf\n","    \"\"\"\n","    Augmenter that leverage two translation models for augmentation. For example, the source is English. This\n","    augmenter translate source to German and translating it back to English. For detail, you may visit\n","    https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28\n","    :param str from_model_name: Any model from https://huggingface.co/models?filter=translation&search=Helsinki-NLP. As\n","        long as from_model_name is pair with to_model_name. For example, from_model_name is English to Japanese,\n","        then to_model_name should be Japanese to English.\n","    :param str to_model_name: Any model from https://huggingface.co/models?filter=translation&search=Helsinki-NLP.\n","    :param str device: Default value is CPU. If value is CPU, it uses CPU for processing. If value is CUDA, it uses GPU\n","        for processing. Possible values include 'cuda' and 'cpu'. (May able to use other options)\n","    :param bool force_reload: Force reload the contextual word embeddings model to memory when initialize the class.\n","        Default value is False and suggesting to keep it as False if performance is the consideration.\n","    :param int batch_size: Batch size.\n","    :param int max_length: The max length of output text.\n","    :param str name: Name of this augmenter\n","    >>> import nlpaug.augmenter.word as naw\n","    >>> aug = naw.BackTranslationAug()\n","    \"\"\"\n","\n","    def __init__(self, from_lang='en', all_langs=['fr','pt'],\n","        name='DeepM2M100BackTranslationAug'):\n","        super().__init__(\n","            action='substitute')\n","        \n","        from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n","\n","        model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n","        tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n","\n","        self.src = from_lang\n","        self.langs = [self.src] + all_langs\n","        self.model = model\n","        self.tokenizer = tokenizer\n","\n","\n","    def substitute(self, data, n=1):\n","\n","        tam = len(self.langs)\n","        texto = data\n","\n","        for i in range(tam - 1):\n","          self.tokenizer.src_lang = self.langs[i]\n","          encoded_hi = self.tokenizer(data, return_tensors=\"pt\")\n","          generated_tokens = self.model.generate(**encoded_hi, forced_bos_token_id=self.tokenizer.get_lang_id(self.langs[i+1]))\n","          texto = self.tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n","\n","        \n","        self.langs.reverse()\n","\n","        for i in range(tam - 1):\n","          self.tokenizer.src_lang = self.langs[i]\n","          encoded_hi = self.tokenizer(data, return_tensors=\"pt\")\n","          generated_tokens = self.model.generate(**encoded_hi, forced_bos_token_id=self.tokenizer.get_lang_id(self.langs[i+1]))\n","          texto = self.tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n","\n","        return texto"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cvZCY44_-Fo_"},"source":["text = 'Filme é muito bom e tem atuações excelentes.'\n","aug = DeepM2M100BackTranslationAug(from_lang='pt', all_langs=['fr', 'de'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jl71zF-n-NDr","executionInfo":{"status":"ok","timestamp":1628647864141,"user_tz":180,"elapsed":1,"user":{"displayName":"Lucas Pellicer","photoUrl":"","userId":"14189643127010164185"}},"outputId":"baad55b6-3e4d-46e9-fc09-00ba214472e0"},"source":["aug.augment(text)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['O filme é muito bom e tem excelentes atuações.']"]},"metadata":{"tags":[]},"execution_count":0}]},{"cell_type":"code","metadata":{"id":"AuRSyzwVxbT7"},"source":["class PegasusPharaphraseAugmenter(WordAugmenter):\n","    # https://arxiv.org/pdf/1511.06709.pdf\n","    \"\"\"\n","    Augmenter that leverage two translation models for augmentation. For example, the source is English. This\n","    augmenter translate source to German and translating it back to English. For detail, you may visit\n","    https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28\n","    :param str from_model_name: Any model from https://huggingface.co/models?filter=translation&search=Helsinki-NLP. As\n","        long as from_model_name is pair with to_model_name. For example, from_model_name is English to Japanese,\n","        then to_model_name should be Japanese to English.\n","    :param str to_model_name: Any model from https://huggingface.co/models?filter=translation&search=Helsinki-NLP.\n","    :param str device: Default value is CPU. If value is CPU, it uses CPU for processing. If value is CUDA, it uses GPU\n","        for processing. Possible values include 'cuda' and 'cpu'. (May able to use other options)\n","    :param bool force_reload: Force reload the contextual word embeddings model to memory when initialize the class.\n","        Default value is False and suggesting to keep it as False if performance is the consideration.\n","    :param int batch_size: Batch size.\n","    :param int max_length: The max length of output text.\n","    :param str name: Name of this augmenter\n","    >>> import nlpaug.augmenter.word as naw\n","    >>> aug = naw.BackTranslationAug()\n","    \"\"\"\n","\n","    def __init__(self,  max_length=60,num_beams=10,temperature=1.5, num_return_sequences = 3,\n","        name='PegasusPharaphraseAugmenter'):\n","        super().__init__(\n","            action='substitute')\n","        \n","        import torch\n","        from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n","        model_name = 'tuner007/pegasus_paraphrase'\n","        torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","        tokenizer = PegasusTokenizer.from_pretrained(model_name)\n","        model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n","\n","        self.model = model\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.num_beams = num_beams\n","        self.temperature = temperature\n","        self.torch_device = torch_device\n","        self.num_return_sequences = num_return_sequences\n","\n","    def substitute(self, data, n = 10):\n","      \n","      \n","      batch = self.tokenizer(data,truncation=True,padding='longest',max_length=self.max_length, return_tensors=\"pt\").to(self.torch_device)\n","      translated = self.model.generate(**batch,max_length=self.max_length,num_beams=self.num_beams, \n","                                       num_return_sequences=self.num_return_sequences, temperature=self.temperature)\n","      tgt_text = self.tokenizer.batch_decode(translated, skip_special_tokens=True)\n","      \n","      return tgt_text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bI91nnhS-uu-"},"source":["text = 'Filme é muito bom e tem atuações excelentes.'\n","aug = DeepGoogleBackTranslationAug(from_lang='pt', all_langs=['fr', 'de'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"KNbBtvrR-u5c","executionInfo":{"status":"ok","timestamp":1628298200141,"user_tz":180,"elapsed":560,"user":{"displayName":"Lucas Pellicer","photoUrl":"","userId":"14189643127010164185"}},"outputId":"2c3765d9-b36b-4354-e21d-5c379c578854"},"source":["aug.augment(text)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'O filme é muito bom e tem uma boa atuação.'"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"CMKf1y52IsyW","colab":{"base_uri":"https://localhost:8080/","height":176,"referenced_widgets":["174468f688b549fda92eb4123da5826b","aa1fbf661f8947759d2e639846a2e86f","1a6d00f7cc324455a67cec57397e8934","b3e80b40e113439ab93848d020761aa8","601769bdbcd84e07877889f61d34ad99","76cbf693701146e48957f5fdeec1a40d","1ca43068b5334808a94d0fc2b880c30b","0a8630b85f6e4633aaff7edd0e8b6956","380982fb62f4480fa4c395babf3b755c","cc073b13b3824bb1b1413908b1d4ba45","8da10083fa9140788d58f778bf1e1374","4f63a35873e64d868e29a6c444ba27f0","e29772a1fe6c4426a04dacf3880c6ca6","d1d17f1c3f934300b5cd04010a7958f8","e2b9e087263147288e38f6eb3d16d9ba","c5de8107c65c4fc798db383cc618b225","5d93babef9a94ef981546d06ae26789e","139860e548be4cc78f74f24c46f01006","3baf725c56854493ae631d6609a87787","a6464a8644564d76957bc22ae5ab53ec","ba1d34f044c04e9786944f1a399e8540","2b1f697f97934461bd63df6570927598","a2df82469ef44ef78ccddc83bab8e591","d3c7d1e9414e48ea985a365a65bed999","d8ae41ca0e8845f68fc35c09f0401641","de180292938a495f8249a3ce08b30da0","4f8a5d899e924067b56a2381496b97d8","63a87bd7f4df48d19524e142749bdfeb","9591d184e42e4a9090a5a0ebe1568fa4","ea266fe7138f487abf61185361019664","305e435fef9342818b77fc23b143bdec","ef4c7d4d429f40d7bc7aa3c575fc25df","3758e8fb66534b52aab26259dce276dc","0b0e0415f8674f5483cd09ecf82979b9","ae324105c609467087905fc68066359a","8311a02872fd4cbdb7ce11bb84dbec93","4c62cdf4e3954730b4d011a5191da502","de144dfbd8e044dda94e251a19a7cf9c","bd4a1ca84d384cde925f7fe33fd2b6cd","aa3ea8dbee924c7994d5624bf704dc73","20cd46e0a1b4417faa7ef9a3a72099f1","0d84cf031abf417d8a3b3d8e9f2bef9f","6185df4614c949e6b6685dc677fe3099","e4f023e316d24ddbad3fca289b612eff","26990e96776a4314a857cc3bc447b545","8a2648e0d4154f9088ae2e2033daca56","38153caae281418ca03a4c9f0d711ed2","2ba54c2ec032438c91378e463b675a20","28a447f4efbc4bc489d8868e052e4f7e","1f038b68c9b44e9bb2b5122c4efa0a68","211a65bab75841fcb9301796974cd7b3","8b28c20100fb4b0ab50880ecb50550ad","3e38d3371bc44cb5b437a4c5c82c5d5d","7f1a7c0f133346d99644e07517627781","a459cd1031ab42dfa86d6dc164748a87"]},"executionInfo":{"status":"ok","timestamp":1628648135357,"user_tz":180,"elapsed":81242,"user":{"displayName":"Lucas Pellicer","photoUrl":"","userId":"14189643127010164185"}},"outputId":"b050c177-c996-46f4-9228-b9a03f3f0bfd"},"source":["text = 'The ultimate test of your knowledge is your capacity to convey it to another.'\n","aug = PegasusPharaphraseAugmenter(num_return_sequences = 10)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"174468f688b549fda92eb4123da5826b","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f63a35873e64d868e29a6c444ba27f0","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2df82469ef44ef78ccddc83bab8e591","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/86.0 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b0e0415f8674f5483cd09ecf82979b9","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.14k [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26990e96776a4314a857cc3bc447b545","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4bTMMEzpI67e","executionInfo":{"status":"ok","timestamp":1628648138655,"user_tz":180,"elapsed":1044,"user":{"displayName":"Lucas Pellicer","photoUrl":"","userId":"14189643127010164185"}},"outputId":"19d52424-2891-4a95-d1d7-61f7798518a7"},"source":["aug.augment(text)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['The test of your knowledge is your ability to convey it.',\n"," 'The ability to convey your knowledge is the ultimate test of your knowledge.',\n"," 'The ability to convey your knowledge is the most important test of your knowledge.',\n"," 'Your capacity to convey your knowledge is the ultimate test of it.',\n"," 'The test of your knowledge is your ability to communicate it.',\n"," 'Your capacity to convey your knowledge is the ultimate test of your knowledge.',\n"," 'Your capacity to convey your knowledge to another is the ultimate test of your knowledge.',\n"," 'Your capacity to convey your knowledge is the most important test of your knowledge.',\n"," 'The test of your knowledge is how well you can convey it.',\n"," 'Your capacity to convey your knowledge is the ultimate test.']"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"qJZdWfYy_psk"},"source":["class PegasusPharaphraseAugmenterOtherLang(WordAugmenter):\n","    # https://arxiv.org/pdf/1511.06709.pdf\n","    \"\"\"\n","    Augmenter that leverage two translation models for augmentation. For example, the source is English. This\n","    augmenter translate source to German and translating it back to English. For detail, you may visit\n","    https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28\n","    :param str from_model_name: Any model from https://huggingface.co/models?filter=translation&search=Helsinki-NLP. As\n","        long as from_model_name is pair with to_model_name. For example, from_model_name is English to Japanese,\n","        then to_model_name should be Japanese to English.\n","    :param str to_model_name: Any model from https://huggingface.co/models?filter=translation&search=Helsinki-NLP.\n","    :param str device: Default value is CPU. If value is CPU, it uses CPU for processing. If value is CUDA, it uses GPU\n","        for processing. Possible values include 'cuda' and 'cpu'. (May able to use other options)\n","    :param bool force_reload: Force reload the contextual word embeddings model to memory when initialize the class.\n","        Default value is False and suggesting to keep it as False if performance is the consideration.\n","    :param int batch_size: Batch size.\n","    :param int max_length: The max length of output text.\n","    :param str name: Name of this augmenter\n","    >>> import nlpaug.augmenter.word as naw\n","    >>> aug = naw.BackTranslationAug()\n","    \"\"\"\n","\n","    def __init__(self, src_lang='pt'  ,max_length=60,num_beams=10,temperature=1.5, num_return_sequences = 3,\n","        name='PegasusPharaphraseAugmenterOtherLang'):\n","        super().__init__(\n","            action='substitute')\n","        \n","        import torch\n","        from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n","        model_name = 'tuner007/pegasus_paraphrase'\n","        torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","        tokenizer = PegasusTokenizer.from_pretrained(model_name)\n","        model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n","\n","        self.src_lang = 'pt'\n","        self.model = model\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.num_beams = num_beams\n","        self.temperature = temperature\n","        self.torch_device = torch_device\n","        self.num_return_sequences = num_return_sequences\n","\n","    def substitute(self, data, n = 10):\n","      from googletrans import Translator\n","      \n","      translator = Translator()\n","      result = translator.translate(data, src = self.src_lang, dest='en')\n","      \n","      \n","      batch = self.tokenizer(result.text,truncation=True,padding='longest',max_length=self.max_length, return_tensors=\"pt\").to(self.torch_device)\n","      translated = self.model.generate(**batch,max_length=self.max_length,num_beams=self.num_beams, \n","                                       num_return_sequences=self.num_return_sequences, temperature=self.temperature)\n","      tgt_text = self.tokenizer.batch_decode(translated, skip_special_tokens=True)\n","\n","      rs_text = []\n","\n","      for t in tgt_text:\n","        fim = translator.translate(t, src = 'en', dest = self.src_lang)\n","        rs_text.append(fim.text)\n","      \n","      return rs_text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9aHnYRMTAo6W"},"source":["text = 'Filme é muito bom e tem atuações excelentes.'\n","aug = PegasusPharaphraseAugmenterOtherLang(src_lang='pt', num_return_sequences = 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7NV_EibIA6jA","executionInfo":{"status":"ok","timestamp":1628648557233,"user_tz":180,"elapsed":2061,"user":{"displayName":"Lucas Pellicer","photoUrl":"","userId":"14189643127010164185"}},"outputId":"b6e761d6-bd7e-40b2-bc31-f3d5decaf067"},"source":["aug.augment(text)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['O filme tem uma boa atuação.',\n"," 'O filme tem uma ótima atuação.',\n"," 'Excelente atuação pode ser vista no filme.',\n"," 'Excelente atuação pode ser encontrada no filme.',\n"," 'O filme tem excelente atuação.',\n"," 'Excelente atuação é o que o filme tem.',\n"," 'O filme é bom e tem uma boa atuação.',\n"," 'O filme tem uma boa atuação.',\n"," 'Excelente atuação é o que o filme tem a oferecer.',\n"," 'O filme tem uma atuação boa e é muito bom.']"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"tQCl-y6xADSY"},"source":["import nlpaug.flow as naf\n","import nlpaug.augmenter.word as naw\n","flow = naf.Sequential([naw.ContextualWordEmbsAug(\n","    model_path='neuralmind/bert-base-portuguese-cased')])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2lQUyoomADXP","executionInfo":{"status":"ok","timestamp":1632265582854,"user_tz":180,"elapsed":8371,"user":{"displayName":"Lucas Pellicer","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14189643127010164185"}},"outputId":"0d8f6577-6e83-45c3-8537-d7c6b38eb41e"},"source":["text = 'Filme é muito bom e tem atuações excelentes.'\n","flow.augment(text, n=10)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"execute_result","data":{"text/plain":["['André é verdadeiramente bom e tem atuações excelentes.',\n"," 'Filme ruim filme bom e tem atuações excelentes.',\n"," 'Filme é muito curto e por atuações excelentes.',\n"," 'Filme é muito bom e mistura atuações interessante.',\n"," 'Filme porno muito bom especialmente tem atuações excelentes.',\n"," 'Filme é muito produzido e ter atuações excelentes.',\n"," 'Filme é muito bom Ele entrega atuações excelentes.',\n"," 'Filme é muito dirigido e tem atuações excelentes.',\n"," 'Filme geral grande bom e tem atuações excelentes.',\n"," 'Filme é muito bom legal tem cores excelentes.']"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":585,"referenced_widgets":["5224058c117443108c02bd457b29f731","93589884d14a4b3382259f29f0db381b","c0c1eb5ba5c9452d85bffc3d5de75b46","5373a7131efb4d1bb5efeff485bdaba4","394ae76084594caabb2cfbd43c612312","1546fdb4142443a4ba4eeca674302013","756155c2d92840a4afc84cf04656ac1d","58d2dee7e8c1441cb257a49dac2e00d4","ad77e336b6b24202a46cc2779c8f61c2","2fd67847caa04a86b4b04dc3d4e78ff2","2799cfdb20d443548d552b0fe17bd138","94835b0a263b4bc7ad8177d2ba3b3b9b","b6443a075571443ea26e161aa60ceb5f","c12c5dbdc28a4b97876a563a3a73bc2b","135be3b61a1e46128988349461c1b5de","aa4a150b4bba4ceaa6660b9917c990b7","0390638c6fd94017aeb38464c0392529","b1ad443897f7410b814a1a8ad70cc4b9","89e452197cbf4605825791ef6f3a570a","780151015e684d28b36faf3f5a2ca888","96e8d093fab44e1e94ab6b1fd45f5279","01df66db0eff4dce960c7a66331396cf","cf5afd7578d042739f31f50838833ece","5a46a208a9a642858361c88f69ea7972","78881852226740849cc207444a726042","2f099e3f39434836830d7d6c5dbb3faf","6aadebddc9db4d33a45f47f1f83512f1","2af7b6ee28cd4f298ac88b135811c05b","20b84a02341149219340f46027891a47","faeb3968f37146a6866aa26664fe6252","4157e3f05fb04e0aafcdc31bf58b1955","5b7f665f1bee477a98ba85a1988fad09","405faf06ba7740b8ba11c6cb33c43703","f4a11b417aeb468baa1cc1b25bdedf60","187654f0d8834e6e9353492c3ea1abee","9851ce9ff2e54843a9bf535b8afdf716","95dbbd7cfa3240d6a95eb192dda20bd8","6e271893d7b543d0978bc95ebbc0eb04","d4fa9cb032db4c1383d767c15593ae9c","a387d888632f4f15adf514b0fa6c8024","d998db54667a4babbb8772540c1d4123","812f7e8e492c4f98b0098fb685150035","cb7d465db4474d2f8b163b41c9b5e3d2","e8d8c05fe9924a8096817bf8c2190694","13ad5f23ff4d420b9689ec4e5602fb75","41688f42fcef4486b7e0241e68910b62","92544db6b9984f8b88991f41efe07a36","a3cbb66c5f8441c28926430ee7dd7ea0","8b653de4e7c74de38d507d0fd5c7056d","347377283f384789ba461706d1f425bd","081d42aa34284d8bb344a7c231a4987d","4c681ff2db4541ab831e1d34f08760ec","7d2080a4a6ec4188b974d03e0cf4862a","310596e2bae94c00ac88d73a43793b8a","75db0d9b375e406483978e52997ba08b"]},"id":"xEFoy1AenPi8","executionInfo":{"status":"error","timestamp":1632265761508,"user_tz":180,"elapsed":15970,"user":{"displayName":"Lucas Pellicer","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14189643127010164185"}},"outputId":"5d2582b5-4978-4875-a5f2-834bacce7618"},"source":["from transformers import pipeline\n","unmasker = pipeline('fill-mask', model='bert-base-cased')\n","unmasker(\"Hello [MASK], I'm a [MASK] model.\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5224058c117443108c02bd457b29f731","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94835b0a263b4bc7ad8177d2ba3b3b9b","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf5afd7578d042739f31f50838833ece","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4a11b417aeb468baa1cc1b25bdedf60","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13ad5f23ff4d420b9689ec4e5602fb75","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"error","ename":"PipelineException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPipelineException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-a72dab79e068>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0munmasker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fill-mask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bert-base-cased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0munmasker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello [MASK], I'm a [MASK] model.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto\u001b[0m \u001b[0mreplace\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, *args, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, inputs, return_tensors, **preprocess_parameters)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_exactly_one_mask_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36mensure_exactly_one_mask_token\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_exactly_one_mask_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_parameters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenericTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m_ensure_exactly_one_mask_token\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;34m\"fill-mask\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0;34mf\"More than one mask_token ({self.tokenizer.mask_token}) is not supported\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             )\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mPipelineException\u001b[0m: More than one mask_token ([MASK]) is not supported"]}]},{"cell_type":"code","metadata":{"id":"xhOG-zZ9ADb4"},"source":["flow = naf.Sequential([naw.RandomWordAug(), DeepGoogleBackTranslationAug(from_lang='pt', all_langs=['fr', 'de'])])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fQv3LqcOADkc","executionInfo":{"status":"ok","timestamp":1627944113063,"user_tz":180,"elapsed":33262,"user":{"displayName":"Lucas Pellicer","photoUrl":"","userId":"14189643127010164185"}},"outputId":"e770fbf1-8e77-42e6-cb3c-23034b82c2de"},"source":["flow.augment(text, n=10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Filme é bom tem atuações excelentes.',\n"," 'Filme é muito e tem atuações.',\n"," 'Filme é muito tem atuações excelentes.',\n"," 'É muito bom tem atuações excelentes.',\n"," 'Filme é muito bom atuações excelentes.',\n"," 'Filme é muito bom tem excelentes.',\n"," 'É muito bom e atuações excelentes.',\n"," 'Filme é muito e atuações excelentes.',\n"," 'Filme bom e tem atuações excelentes.',\n"," 'Filme é bom e tem atuações.']"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"4aQZDTgrB2Md"},"source":["flow = naf.Sequential([naw.RandomWordAug(aug_p=0.3), naw.ContextualWordEmbsAug(model_path='neuralmind/bert-base-portuguese-cased',aug_p=0.3)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JqLKx5_iGqzz","executionInfo":{"status":"ok","timestamp":1627945354709,"user_tz":180,"elapsed":2568,"user":{"displayName":"Lucas Pellicer","photoUrl":"","userId":"14189643127010164185"}},"outputId":"006fd365-8449-416f-bbc5-0bd06711af15"},"source":["flow.augment(text, n=10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Homem é grande tem atuações excelentes.',\n"," 'É muito bom e cobra vendas excelentes.',\n"," 'Filme original muito bom essas atuações.',\n"," 'É muito bom vários vídeos excelentes.',\n"," 'Filme é muito para atuações claras.',\n"," 'Ele particularmente bom e atuações excelentes.',\n"," 'Filme bom certamente tem outras excelentes.',\n"," 'É compositor bom e das atuações excelentes.',\n"," 'Filme é muito romântico trechos excelentes.',\n"," 'Filme muito bom e preciso demais.']"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":263},"id":"09jiR5_EJfBb","executionInfo":{"status":"ok","timestamp":1627946640750,"user_tz":180,"elapsed":235,"user":{"displayName":"Lucas Pellicer","photoUrl":"","userId":"14189643127010164185"}},"outputId":"35be747d-8d16-48c6-cba6-8bbe5450c4bc"},"source":["import pandas as pd\n","data = pd.read_csv('nlpaug/test/res/text/classification.csv')\n","data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>My hope lay in Jack's promise that he would ke...</td>\n","      <td>LABEL_0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Dotty continued to go to Mrs. Gray's every nig...</td>\n","      <td>LABEL_1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>It was a bright and cheerful scene that greete...</td>\n","      <td>LABEL_0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Cell division is the process by which a parent...</td>\n","      <td>LABEL_2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Debugging is the process of finding and resolv...</td>\n","      <td>LABEL_1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>To explain transitivity, let us look first at ...</td>\n","      <td>LABEL_2</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Milka and John are playing in the garden. Her ...</td>\n","      <td>LABEL_2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text    label\n","0  My hope lay in Jack's promise that he would ke...  LABEL_0\n","1  Dotty continued to go to Mrs. Gray's every nig...  LABEL_1\n","2  It was a bright and cheerful scene that greete...  LABEL_0\n","3  Cell division is the process by which a parent...  LABEL_2\n","4  Debugging is the process of finding and resolv...  LABEL_1\n","5  To explain transitivity, let us look first at ...  LABEL_2\n","6  Milka and John are playing in the garden. Her ...  LABEL_2"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uyZgeUJFJ7DB","executionInfo":{"status":"ok","timestamp":1627946778789,"user_tz":180,"elapsed":96388,"user":{"displayName":"Lucas Pellicer","photoUrl":"","userId":"14189643127010164185"}},"outputId":"6619f48b-8d79-4b0e-8042-6622c34d4bd2"},"source":["!python nlpaug/scripts/lambada/train_cls.py  \\\n","    --train_data_path nlpaug/test/res/text/classification.csv \\\n","    --val_data_path nlpaug/test/res/text/classification.csv \\\n","    --output_dir nlpaug/model/lambada/cls \\\n","    --device cpu \\\n","    --num_epoch 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-08-02 23:24:41.417609: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","Downloading: 100% 501M/501M [00:12<00:00, 40.5MB/s]\n","Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Downloading: 100% 899k/899k [00:00<00:00, 12.6MB/s]\n","Downloading: 100% 456k/456k [00:00<00:00, 8.21MB/s]\n","Downloading: 100% 1.36M/1.36M [00:00<00:00, 15.6MB/s]\n","/usr/local/lib/python3.7/dist-packages/simpletransformers/classification/classification_model.py:616: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n","  \"Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\"\n"," 14% 1/7 [00:00<00:01,  5.86it/s]\n","Epoch 1 of 2:   0% 0/2 [00:00<?, ?it/s]\n","Running Epoch 0 of 2:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Epochs 0/2. Running Loss:    1.1239:   0% 0/1 [00:09<?, ?it/s]\u001b[A\n","Epochs 0/2. Running Loss:    1.1239: 100% 1/1 [00:24<00:00, 24.11s/it]\n","Epoch 2 of 2:  50% 1/2 [00:29<00:29, 29.22s/it]\n","Running Epoch 1 of 2:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Epochs 1/2. Running Loss:    1.1190:   0% 0/1 [00:08<?, ?it/s]\u001b[A\n","Epochs 1/2. Running Loss:    1.1190: 100% 1/1 [00:23<00:00, 23.20s/it]\n","Epoch 2 of 2: 100% 2/2 [00:57<00:00, 28.52s/it]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uQ-r_Mi5J7TK"},"source":["\n","!python nlpaug/scripts/lambada/data_processing.py \\\n","    --data_path nlpaug/test/res/text/classification.csv \\\n","    --output_dir nlpaug/test/res/text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ot93dT2fJ7XZ","executionInfo":{"status":"ok","timestamp":1627946980170,"user_tz":180,"elapsed":147015,"user":{"displayName":"Lucas Pellicer","photoUrl":"","userId":"14189643127010164185"}},"outputId":"9b73df28-2c52-4b31-e682-992efeb9acd0"},"source":["!source activate py39; python nlpaug/scripts/lambada/run_clm.py \\\n","    --tokenizer_name nlpaug/model/lambada/cls \\\n","    --model_name_or_path gpt2 \\\n","    --model_type gpt2 \\\n","    --train_file nlpaug/test/res/text/mlm_data.txt \\\n","    --output_dir nlpaug/model/lambada/gen \\\n","    --do_train \\\n","    --overwrite_output_dir \\\n","    --per_device_train_batch_size 4 \\\n","    --per_device_eval_batch_size 4 \\\n","    --save_steps=10000 \\\n","    --num_train_epochs 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/bin/bash: activate: No such file or directory\n","2021-08-02 23:27:12.427803: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","08/02/2021 23:27:15 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n","08/02/2021 23:27:15 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n","_n_gpu=0,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_find_unused_parameters=None,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=False,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_steps=None,\n","evaluation_strategy=IntervalStrategy.NO,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","gradient_accumulation_steps=1,\n","greater_is_better=None,\n","group_by_length=False,\n","ignore_data_skip=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=-1,\n","log_level_replica=-1,\n","log_on_each_node=True,\n","logging_dir=nlpaug/model/lambada/gen/runs/Aug02_23-27-15_662fd1493229,\n","logging_first_step=False,\n","logging_steps=500,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=2.0,\n","output_dir=nlpaug/model/lambada/gen,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=gen,\n","push_to_hub_organization=None,\n","push_to_hub_token=None,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=nlpaug/model/lambada/gen,\n","save_on_each_node=False,\n","save_steps=10000,\n","save_strategy=IntervalStrategy.STEPS,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_legacy_prediction_loop=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","08/02/2021 23:27:15 - WARNING - datasets.builder -   Using custom data configuration default-97f32c8a957447cd\n","Downloading and preparing dataset text/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/text/default-97f32c8a957447cd/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n","Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-97f32c8a957447cd/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n","[INFO|file_utils.py:1631] 2021-08-02 23:27:15,752 >> https://huggingface.co/gpt2/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp7cevtqpb\n","Downloading: 100% 665/665 [00:00<00:00, 523kB/s]\n","[INFO|file_utils.py:1635] 2021-08-02 23:27:15,929 >> storing https://huggingface.co/gpt2/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n","[INFO|file_utils.py:1643] 2021-08-02 23:27:15,930 >> creating metadata file for /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n","[INFO|configuration_utils.py:545] 2021-08-02 23:27:15,930 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n","[INFO|configuration_utils.py:581] 2021-08-02 23:27:15,931 >> Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.10.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","[INFO|tokenization_utils_base.py:1664] 2021-08-02 23:27:15,931 >> Didn't find file nlpaug/model/lambada/cls/added_tokens.json. We won't load it.\n","[INFO|tokenization_utils_base.py:1728] 2021-08-02 23:27:15,932 >> loading file nlpaug/model/lambada/cls/vocab.json\n","[INFO|tokenization_utils_base.py:1728] 2021-08-02 23:27:15,932 >> loading file nlpaug/model/lambada/cls/merges.txt\n","[INFO|tokenization_utils_base.py:1728] 2021-08-02 23:27:15,932 >> loading file nlpaug/model/lambada/cls/tokenizer.json\n","[INFO|tokenization_utils_base.py:1728] 2021-08-02 23:27:15,932 >> loading file None\n","[INFO|tokenization_utils_base.py:1728] 2021-08-02 23:27:15,932 >> loading file nlpaug/model/lambada/cls/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:1728] 2021-08-02 23:27:15,932 >> loading file nlpaug/model/lambada/cls/tokenizer_config.json\n","[INFO|file_utils.py:1631] 2021-08-02 23:27:16,100 >> https://huggingface.co/gpt2/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpex99xsp_\n","Downloading: 100% 548M/548M [00:15<00:00, 36.0MB/s]\n","[INFO|file_utils.py:1635] 2021-08-02 23:27:31,583 >> storing https://huggingface.co/gpt2/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n","[INFO|file_utils.py:1643] 2021-08-02 23:27:31,583 >> creating metadata file for /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n","[INFO|modeling_utils.py:1271] 2021-08-02 23:27:31,584 >> loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n","[INFO|modeling_utils.py:1510] 2021-08-02 23:27:33,554 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","[INFO|modeling_utils.py:1519] 2021-08-02 23:27:33,554 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Running tokenizer on dataset: 100% 1/1 [00:00<00:00,  4.24ba/s]\n","Grouping texts in chunks of 512: 100% 1/1 [00:00<00:00, 10.32ba/s]\n","[INFO|trainer.py:1164] 2021-08-02 23:27:34,620 >> ***** Running training *****\n","[INFO|trainer.py:1165] 2021-08-02 23:27:34,620 >>   Num examples = 1\n","[INFO|trainer.py:1166] 2021-08-02 23:27:34,620 >>   Num Epochs = 2\n","[INFO|trainer.py:1167] 2021-08-02 23:27:34,620 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:1168] 2021-08-02 23:27:34,620 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n","[INFO|trainer.py:1169] 2021-08-02 23:27:34,620 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1170] 2021-08-02 23:27:34,620 >>   Total optimization steps = 2\n","100% 2/2 [01:59<00:00, 51.76s/it] [INFO|trainer.py:1362] 2021-08-02 23:29:34,299 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 119.6793, 'train_samples_per_second': 0.017, 'train_steps_per_second': 0.017, 'train_loss': 45.10634231567383, 'epoch': 2.0}\n","100% 2/2 [01:59<00:00, 59.82s/it]\n","[INFO|trainer.py:1921] 2021-08-02 23:29:34,302 >> Saving model checkpoint to nlpaug/model/lambada/gen\n","[INFO|configuration_utils.py:379] 2021-08-02 23:29:34,303 >> Configuration saved in nlpaug/model/lambada/gen/config.json\n","[INFO|modeling_utils.py:997] 2021-08-02 23:29:35,544 >> Model weights saved in nlpaug/model/lambada/gen/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2006] 2021-08-02 23:29:35,545 >> tokenizer config file saved in nlpaug/model/lambada/gen/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2012] 2021-08-02 23:29:35,552 >> Special tokens file saved in nlpaug/model/lambada/gen/special_tokens_map.json\n","***** train metrics *****\n","  epoch                    =        2.0\n","  train_loss               =    45.1063\n","  train_runtime            = 0:01:59.67\n","  train_samples            =          1\n","  train_samples_per_second =      0.017\n","  train_steps_per_second   =      0.017\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Akn7K_NMWan","executionInfo":{"status":"ok","timestamp":1627947110958,"user_tz":180,"elapsed":3957,"user":{"displayName":"Lucas Pellicer","photoUrl":"","userId":"14189643127010164185"}},"outputId":"3bf42ab5-667a-4cf6-afda-edbc6e3be295"},"source":["import nlpaug.augmenter.sentence as nas\n","aug = nas.LambadaAug(model_dir='nlpaug/model/lambada', threshold=0.3, batch_size=4)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n","The class this function is called from is 'GPT2Tokenizer'.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"id":"KaAgjCi4MWnE","executionInfo":{"status":"ok","timestamp":1627947572359,"user_tz":180,"elapsed":442160,"user":{"displayName":"Lucas Pellicer","photoUrl":"","userId":"14189643127010164185"}},"outputId":"524cdb00-c145-4976-fb07-d0957b7c1c09"},"source":["aug.augment(['LABEL_0', 'LABEL_1', 'LABEL_2'], n=10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>pred</th>\n","      <th>prob</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td></td>\n","      <td>LABEL_0</td>\n","      <td>LABEL_0</td>\n","      <td>0.3471</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td></td>\n","      <td>LABEL_0</td>\n","      <td>LABEL_0</td>\n","      <td>0.3471</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td></td>\n","      <td>LABEL_0</td>\n","      <td>LABEL_0</td>\n","      <td>0.3471</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>madeupword0000</td>\n","      <td>LABEL_0</td>\n","      <td>LABEL_0</td>\n","      <td>0.3475</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td></td>\n","      <td>LABEL_0</td>\n","      <td>LABEL_0</td>\n","      <td>0.3471</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>madeupword0000madeupword0000</td>\n","      <td>LABEL_0</td>\n","      <td>LABEL_0</td>\n","      <td>0.3484</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td></td>\n","      <td>LABEL_0</td>\n","      <td>LABEL_0</td>\n","      <td>0.3471</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td></td>\n","      <td>LABEL_0</td>\n","      <td>LABEL_0</td>\n","      <td>0.3471</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td></td>\n","      <td>LABEL_0</td>\n","      <td>LABEL_0</td>\n","      <td>0.3471</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td></td>\n","      <td>LABEL_0</td>\n","      <td>LABEL_0</td>\n","      <td>0.3471</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                          text    label     pred    prob\n","0   0                                LABEL_0  LABEL_0  0.3471\n","1   1                                LABEL_0  LABEL_0  0.3471\n","2   2                                LABEL_0  LABEL_0  0.3471\n","3   3                madeupword0000  LABEL_0  LABEL_0  0.3475\n","4   4                                LABEL_0  LABEL_0  0.3471\n","5   5  madeupword0000madeupword0000  LABEL_0  LABEL_0  0.3484\n","6   6                                LABEL_0  LABEL_0  0.3471\n","7   7                                LABEL_0  LABEL_0  0.3471\n","8   8                                LABEL_0  LABEL_0  0.3471\n","9   9                                LABEL_0  LABEL_0  0.3471"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"ESE6uTU0MWs0"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ql3WTdTMYrb"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PSC45vboMYu3"},"source":[],"execution_count":null,"outputs":[]}]}